{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"gpt-4-turbo\",\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "    \"together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "]\n",
    "tags = [\n",
    "    \"benchmark_gpt-4-turbo_gpt-4o_gpt-4o_haicosystem_trial2\",\n",
    "    \"benchmark_gpt-3.5-turbo_gpt-4o_gpt-4o_haicosystem_trial2\",\n",
    "    \"benchmark_together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo_gpt-4o-2024-08-06_gpt-4o-2024-08-06_haicosystem_trial2\",\n",
    "    \"benchmark_together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo_gpt-4o-2024-08-06_gpt-4o-2024-08-06_haicosystem_trial2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "models_mapping = {\n",
    "    \"gpt-4-turbo\": \"GPT-4-turbo\",\n",
    "    \"gpt-3.5-turbo\": \"GPT-3.5-turbo\",\n",
    "    \"together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\": \"Llama3-70B\",\n",
    "    \"together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\": \"Llama3-405B\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sec 6.1: main results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get performance and ratio data\n",
    "from sotopia.database import EpisodeLog\n",
    "\n",
    "from haicosystem.protocols import HaiEnvironmentProfile\n",
    "from haicosystem.utils import get_avg_reward\n",
    "\n",
    "performance_data = {}\n",
    "ratio_data = {}\n",
    "model_rewards = {}\n",
    "for model, tag in zip(models, tags):\n",
    "    episodes = EpisodeLog.find(EpisodeLog.tag == tag).all()\n",
    "    avg_rewards = get_avg_reward(episodes, model)  # type: ignore\n",
    "    binary_avg_rewards = get_avg_reward(episodes, model, binary=True)  # type: ignore\n",
    "    performance_data[model] = avg_rewards\n",
    "    ratio_data[model] = binary_avg_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(performance, models, wrap=True):\n",
    "    # Define the table dimensions and labels\n",
    "    dimensions = {\n",
    "        \"targeted_safety_risks\": \"Targeted Safety Risks & [-10, 0]\",\n",
    "        \"system_and_operational_risks\": \"System and Operational Risks & [-10, 0]\",\n",
    "        \"content_safety_risks\": \"Content Safety Risks & [-10, 0]\",\n",
    "        \"societal_risks\": \"Societal Risks & [-10, 0]\",\n",
    "        \"legal_and_rights_related_risks\": \"Legal and Rights-Related Risks & [-10, 0]\",\n",
    "        \"efficiency\": \"Efficiency & [0, 10]\",\n",
    "        \"goal\": \"Goal Completion & [0, 10]\",\n",
    "    }\n",
    "    # Start building the LaTeX code\n",
    "    # Start building the LaTeX code\n",
    "    if wrap:\n",
    "        latex_code = \"\"\"\n",
    "\\\\begin{wraptable}[13]{r}{8.7cm}\n",
    "\\\\small\n",
    "\\\\vspace{-10pt}\n",
    "\\\\centering\n",
    "\"\"\"\n",
    "    else:\n",
    "        latex_code = \"\"\"\n",
    "\\\\begin{table}[h]\n",
    "\\\\small\n",
    "\\\\centering\n",
    "\"\"\"\n",
    "    latex_code += (\n",
    "        \"    \\\\begin{tabularx}{8.7cm}{@{\\\\hspace{10pt}}\"\n",
    "        + \"r\" * (len(models) + 2)\n",
    "        + \"@{\\\\hspace{6pt}}}\\n\"\n",
    "    )\n",
    "    latex_code += \"    \\\\toprule\\n\"\n",
    "    latex_code += \"         Dimension & Range \"\n",
    "\n",
    "    # Add model headers to the table\n",
    "    for model in models:\n",
    "        latex_code += f\"& {models_mapping[model]} \"\n",
    "    latex_code += \"\\\\\\\\ \\\\midrule\\n\"\n",
    "\n",
    "    # Populate the table with data\n",
    "    for dim_key, dim_label in dimensions.items():\n",
    "        latex_code += f\"         {dim_label} \"\n",
    "        for model in models:\n",
    "            if model in performance and dim_key in performance[model]:\n",
    "                value = performance[model][dim_key][0]\n",
    "                latex_code += f\"& {value:.2f} \"\n",
    "            else:\n",
    "                latex_code += \"& \"\n",
    "        latex_code += \"\\\\\\\\ \\n\"\n",
    "\n",
    "    # Close the table\n",
    "    latex_code += \"\"\"    \\\\bottomrule\n",
    "    \\\\end{tabularx}\n",
    "    \\\\vspace{-5pt}\n",
    "    \\\\caption{The aggregated performance of each model by averaging across different episodes.}\n",
    "    \\\\label{tab:model_safety_evaluation}\n",
    "\"\"\"\n",
    "    if wrap:\n",
    "        latex_code += \"\\\\end{wraptable}\\n\"\n",
    "    else:\n",
    "        latex_code += \"\\\\end{table}\\n\"\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = generate_latex_table(\n",
    "    performance=performance_data,\n",
    "    models=models,\n",
    "    wrap=False,\n",
    ")\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk ratio graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def generate_bar_graph(\n",
    "    ratio_data: Dict[str, Dict[str, Tuple[float, float]]], save_path: str = \"\"\n",
    ") -> None:\n",
    "    # Define the categories to include in the graph\n",
    "    categories = [\n",
    "        \"overall_score\",\n",
    "        \"targeted_safety_risks\",\n",
    "        \"system_and_operational_risks\",\n",
    "        \"content_safety_risks\",\n",
    "        \"societal_risks\",\n",
    "        \"legal_and_rights_related_risks\",\n",
    "    ]\n",
    "    category_acronyms = {\n",
    "        \"overall_score\": \"Overall\",\n",
    "        \"targeted_safety_risks\": \"Tar.R\",\n",
    "        \"system_and_operational_risks\": \"Sys.R\",\n",
    "        \"content_safety_risks\": \"Con.R\",\n",
    "        \"societal_risks\": \"Soc.R\",\n",
    "        \"legal_and_rights_related_risks\": \"Legal.R\",\n",
    "    }\n",
    "\n",
    "    # Initialize data containers for plotting\n",
    "    models = list(ratio_data.keys())\n",
    "    number_of_models = len(models)\n",
    "    category_values = {category: [] for category in categories}\n",
    "\n",
    "    # Extract the data\n",
    "    for model in models:\n",
    "        for category in categories:\n",
    "            value = ratio_data[model].get(category, (0.0, 0.0))[0]\n",
    "            category_values[category].append(value)\n",
    "\n",
    "    # Set up Seaborn's style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Create a new figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))  # Smaller figure size\n",
    "\n",
    "    # Define color palette (blues)\n",
    "    palette = sns.color_palette(\"Blues\", len(models))\n",
    "\n",
    "    # Plot bars for each model\n",
    "    bar_width = 0.2  # Width of the bars\n",
    "    index = range(len(categories))  # X locations for the groups\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        bars = ax.bar(\n",
    "            [p + i * bar_width for p in index],\n",
    "            [category_values[cat][i] for cat in categories],\n",
    "            bar_width,\n",
    "            label=models_mapping[model],\n",
    "            color=palette[i],\n",
    "        )\n",
    "        # Add numbers on top of bars\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                yval + 0.01,\n",
    "                f\"{yval:.2f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=10,\n",
    "            )\n",
    "\n",
    "    # Labels, title, and legend\n",
    "    ax.set_ylabel(\"Risk Ratio\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_xticks([p + (bar_width * (len(models) - 1) / 2) for p in index])\n",
    "    ax.set_xticklabels([category_acronyms[cat] for cat in categories], fontsize=12)\n",
    "    ax.legend(\n",
    "        title=\"Models\",\n",
    "        title_fontsize=\"13\",\n",
    "        fontsize=\"11\",\n",
    "        loc=\"best\",\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "    )\n",
    "    sns.despine()\n",
    "    # Improve visual spacing\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_bar_graph(ratio_data=ratio_data, save_path=\"./risk_ratio_graph.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from sotopia.database import EpisodeLog\n",
    "\n",
    "from haicosystem.protocols import HaiEnvironmentProfile\n",
    "\n",
    "\n",
    "def compare_across_models(tags: list[str]) -> list[list[str]]:\n",
    "    assert len(tags) == 2, \"The function only supports two tags for comparison.\"\n",
    "    # Get the performance data for each tag\n",
    "    episodes_with_tag1 = EpisodeLog.find(EpisodeLog.tag == tags[0]).all()\n",
    "    episodes_with_tag2 = EpisodeLog.find(EpisodeLog.tag == tags[1]).all()\n",
    "    env_agent_combo = defaultdict(list)\n",
    "    for episode in episodes_with_tag1:\n",
    "        key_string = \";\".join(\n",
    "            [episode.environment, episode.agents[0], episode.agents[1]]\n",
    "        )\n",
    "        env_agent_combo[key_string].append(episode)\n",
    "    for episode in episodes_with_tag2:\n",
    "        key_string = \";\".join(\n",
    "            [episode.environment, episode.agents[0], episode.agents[1]]\n",
    "        )\n",
    "        env_agent_combo[key_string].append(episode)\n",
    "\n",
    "    # Compare the performance of the two tags\n",
    "    comparison_results = []\n",
    "    for key, episodes in env_agent_combo.items():\n",
    "        environment = HaiEnvironmentProfile.get(key.split(\";\")[0])\n",
    "        codename = environment.codename\n",
    "        if len(episodes) == 2:\n",
    "            episode1, episode2 = episodes\n",
    "            performance1 = episode1.rewards[1][1][\"targeted_safety_risks\"]\n",
    "            performance2 = episode2.rewards[1][1][\"targeted_safety_risks\"]\n",
    "            comparison_results.append([codename, performance1, performance2])\n",
    "    return comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "\n",
    "comparison = compare_across_models(\n",
    "    tags=[\n",
    "        \"benchmark_together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo_gpt-4o-2024-08-06_gpt-4o-2024-08-06_haicosystem_trial2\",\n",
    "        \"benchmark_together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo_gpt-4o-2024-08-06_gpt-4o-2024-08-06_haicosystem_trial2\",\n",
    "    ]\n",
    ")\n",
    "rich.print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sec 6.2: human intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the data\n",
    "from sotopia.database import EpisodeLog\n",
    "\n",
    "from haicosystem.protocols import HaiEnvironmentProfile\n",
    "from haicosystem.utils import get_avg_reward\n",
    "\n",
    "model_rewards = {}\n",
    "for model, tag in zip(models, tags):\n",
    "    episodes = EpisodeLog.find(EpisodeLog.tag == tag).all()\n",
    "    benign_intent_episodes = []\n",
    "    malicious_intent_episodes = []\n",
    "    for episode in episodes:\n",
    "        env = HaiEnvironmentProfile.get(episode.environment)\n",
    "        if env.agent_intent_labels[0] == \"benign\":\n",
    "            benign_intent_episodes.append(episode)\n",
    "        else:\n",
    "            malicious_intent_episodes.append(episode)\n",
    "    benign_binary_avg_rewards = get_avg_reward(\n",
    "        benign_intent_episodes, model, binary=True\n",
    "    )  # type: ignore\n",
    "    malicious_binary_avg_rewards = get_avg_reward(\n",
    "        malicious_intent_episodes, model, binary=True\n",
    "    )  # type: ignore\n",
    "    model_rewards[model] = (benign_binary_avg_rewards, malicious_binary_avg_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def draw_overall_score_bar_plot(\n",
    "    data: Dict[\n",
    "        str, Tuple[Dict[str, Tuple[float, float]], Dict[str, Tuple[float, float]]]\n",
    "    ],\n",
    "    save_path: str,\n",
    ") -> None:\n",
    "    # Prepare data for plotting\n",
    "    models = []\n",
    "    scores = []\n",
    "    intents = []\n",
    "\n",
    "    for model_name, (benign, malicious) in data.items():\n",
    "        models.append(models_mapping[model_name])\n",
    "        scores.append(benign[\"overall_score\"][0])\n",
    "        intents.append(\"Benign\")\n",
    "\n",
    "        models.append(models_mapping[model_name])\n",
    "        scores.append(malicious[\"overall_score\"][0])\n",
    "        intents.append(\"Malicious\")\n",
    "\n",
    "    # Create a DataFrame for easier plotting\n",
    "    plot_data = {\"Model\": models, \"Overall Score\": scores, \"Intent\": intents}\n",
    "    # Set up the color palette\n",
    "    palette = {\"Benign\": \"#A2CA71\", \"Malicious\": \"#F6E96B\"}\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    ax = sns.barplot(\n",
    "        x=\"Model\", y=\"Overall Score\", hue=\"Intent\", data=plot_data, palette=palette\n",
    "    )\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Overall Risk Ratio\")\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        if height > 0:  # Only annotate bars with a positive height\n",
    "            ax.annotate(\n",
    "                f\"{height:.2f}\",\n",
    "                (p.get_x() + p.get_width() / 2.0, height),\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",  # Adjust the vertical alignment to be 'bottom'\n",
    "                xytext=(0, 8),\n",
    "                textcoords=\"offset points\",\n",
    "                fontsize=10,\n",
    "                color=\"black\",\n",
    "            )\n",
    "\n",
    "    # Improve visual spacing\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.legend(title=\"Intent\", title_fontsize=\"10\", fontsize=\"8\")\n",
    "\n",
    "    # Improve layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "draw_overall_score_bar_plot(model_rewards, save_path=\"./human_intent_plot.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sec 6.3: Access to the tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def draw_efficiency_goal_bar_plot(\n",
    "    data: Dict[str, Dict[str, Tuple[float, float]]], save_path: str = None\n",
    ") -> None:\n",
    "    # Prepare data for plotting\n",
    "    models = []\n",
    "    scores = []\n",
    "    metrics = []\n",
    "\n",
    "    for model_name, metrics_dict in data.items():\n",
    "        models.append(models_mapping[model_name])\n",
    "        scores.append(\n",
    "            metrics_dict[\"efficiency\"][0]\n",
    "        )  # Use the first element of the tuple for efficiency\n",
    "        metrics.append(\"Efficiency\")\n",
    "\n",
    "        models.append(models_mapping[model_name])\n",
    "        scores.append(\n",
    "            metrics_dict[\"goal\"][0]\n",
    "        )  # Use the first element of the tuple for goal\n",
    "        metrics.append(\"Goal\")\n",
    "\n",
    "    # Create a DataFrame for easier plotting\n",
    "    plot_data = {\"Model\": models, \"Score\": scores, \"Metric\": metrics}\n",
    "\n",
    "    # Set up the color palette\n",
    "    palette = {\"Efficiency\": \"#69db7c\", \"Goal\": \"#4dabf7\"}\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    ax = sns.barplot(\n",
    "        x=\"Model\", y=\"Score\", hue=\"Metric\", data=plot_data, palette=palette\n",
    "    )\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(min(scores) - 1, max(scores) + 1)\n",
    "\n",
    "    # Add the scores above the bars\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.annotate(\n",
    "            f\"{height:.2f}\",\n",
    "            (p.get_x() + p.get_width() / 2.0, height),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",  # Adjust the vertical alignment to be 'bottom'\n",
    "            xytext=(0, 8),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=10,\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "    # Improve visual spacing\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.legend(title=\"Metric\", title_fontsize=\"10\", fontsize=\"8\")\n",
    "\n",
    "    # Improve layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "draw_efficiency_goal_bar_plot(performance_data, save_path=\"./efficiency_goal_plot.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haicosystem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
