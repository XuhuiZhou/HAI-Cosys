{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"gpt-4-turbo\",\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "    \"together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "]\n",
    "tags = [\n",
    "    \"benchmark_gpt-4-turbo_gpt-4o-2024-08-06_gpt-4o-2024-08-06_haicosystem_trial2\",\n",
    "    \"benchmark_gpt-3.5-turbo_gpt-4o-2024-08-06_gpt-4o-2024-08-06_haicosystem_trial2\",\n",
    "    \"benchmark_together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo_gpt-4o-2024-08-06_gpt-4o-2024-08-06_haicosystem_trial2\",\n",
    "    \"benchmark_together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo_gpt-4o-2024-08-06_gpt-4o-2024-08-06_haicosystem_trial2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "models_mapping = {\n",
    "    \"gpt-4-turbo\": \"GPT-4-turbo\",\n",
    "    \"gpt-3.5-turbo\": \"GPT-3.5-turbo\",\n",
    "    \"together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\": \"Llama3-70B\",\n",
    "    \"together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\": \"Llama3-405B\",\n",
    "}\n",
    "\n",
    "performance_data = {\n",
    "    \"gpt-4-turbo\": {\n",
    "        \"targeted_safety_risks\": (-3.5434782608695654, 0.0),\n",
    "        \"system_and_operational_risks\": (-2.4456521739130435, 0.0),\n",
    "        \"content_safety_risks\": (-1.5978260869565217, 0.0),\n",
    "        \"societal_risks\": (-2.1847826086956523, 0.0),\n",
    "        \"legal_and_rights_related_risks\": (-2.3369565217391304, 0.0),\n",
    "        \"efficiency\": (7.391304347826087, 0.0),\n",
    "        \"goal\": (7.163043478260869, 0.0),\n",
    "        \"overall_score\": (0.3493788819875778, 0.0),\n",
    "        \"setting_num\": (92.0, 0.0),\n",
    "        \"episode_count\": (92.0, 0.0),\n",
    "    },\n",
    "    \"gpt-3.5-turbo\": {\n",
    "        \"targeted_safety_risks\": (-4.706521739130435, 0.0),\n",
    "        \"system_and_operational_risks\": (-3.608695652173913, 0.0),\n",
    "        \"content_safety_risks\": (-2.402173913043478, 0.0),\n",
    "        \"societal_risks\": (-2.989130434782609, 0.0),\n",
    "        \"legal_and_rights_related_risks\": (-2.989130434782609, 0.0),\n",
    "        \"efficiency\": (5.75, 0.0),\n",
    "        \"goal\": (5.336956521739131, 0.0),\n",
    "        \"overall_score\": (-0.8012422360248445, 0.0),\n",
    "        \"setting_num\": (92.0, 0.0),\n",
    "        \"episode_count\": (92.0, 0.0),\n",
    "    },\n",
    "}\n",
    "\n",
    "ratio_data = {\n",
    "    \"gpt-4-turbo\": {\n",
    "        \"targeted_safety_risks\": (0.5434782608695652, 0.0),\n",
    "        \"system_and_operational_risks\": (0.45652173913043476, 0.0),\n",
    "        \"content_safety_risks\": (0.2717391304347826, 0.0),\n",
    "        \"societal_risks\": (0.358695652173913, 0.0),\n",
    "        \"legal_and_rights_related_risks\": (0.3804347826086957, 0.0),\n",
    "        \"efficiency\": (0.0, 0.0),\n",
    "        \"goal\": (0.0, 0.0),\n",
    "        \"overall_score\": (0.5543478260869565, 0.0),\n",
    "        \"setting_num\": (92.0, 0.0),\n",
    "        \"episode_count\": (92.0, 0.0),\n",
    "    },\n",
    "    \"gpt-3.5-turbo\": {\n",
    "        \"targeted_safety_risks\": (0.6739130434782609, 0.0),\n",
    "        \"system_and_operational_risks\": (0.6521739130434783, 0.0),\n",
    "        \"content_safety_risks\": (0.40217391304347827, 0.0),\n",
    "        \"societal_risks\": (0.5, 0.0),\n",
    "        \"legal_and_rights_related_risks\": (0.5, 0.0),\n",
    "        \"efficiency\": (0.0, 0.0),\n",
    "        \"goal\": (0.0, 0.0),\n",
    "        \"overall_score\": (0.6847826086956522, 0.0),\n",
    "        \"setting_num\": (92.0, 0.0),\n",
    "        \"episode_count\": (92.0, 0.0),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sec 6.1: main results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get performance and ratio data\n",
    "from sotopia.database import EpisodeLog\n",
    "\n",
    "from haicosystem.protocols import HaiEnvironmentProfile\n",
    "from haicosystem.utils import get_avg_reward\n",
    "\n",
    "performance_data = {}\n",
    "ratio_data = {}\n",
    "model_rewards = {}\n",
    "for model, tag in zip(models, tags):\n",
    "    episodes = EpisodeLog.find(EpisodeLog.tag == tag).all()\n",
    "    avg_rewards = get_avg_reward(episodes, model)  # type: ignore\n",
    "    binary_avg_rewards = get_avg_reward(episodes, model, binary=True)  # type: ignore\n",
    "    performance_data[model] = avg_rewards\n",
    "    ratio_data[model] = binary_avg_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(performance, models, wrap=True):\n",
    "    # Define the table dimensions and labels\n",
    "    dimensions = {\n",
    "        \"targeted_safety_risks\": \"Targeted Safety Risks & [-10, 0]\",\n",
    "        \"system_and_operational_risks\": \"System and Operational Risks & [-10, 0]\",\n",
    "        \"content_safety_risks\": \"Content Safety Risks & [-10, 0]\",\n",
    "        \"societal_risks\": \"Societal Risks & [-10, 0]\",\n",
    "        \"legal_and_rights_related_risks\": \"Legal and Rights-Related Risks & [-10, 0]\",\n",
    "        \"efficiency\": \"Efficiency & [0, 10]\",\n",
    "        \"goal\": \"Goal Completion & [0, 10]\",\n",
    "    }\n",
    "    models_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4\",\n",
    "        \"gpt-3.5-turbo\": \"GPT-3.5\",\n",
    "        \"llama3\": \"Llama3\",\n",
    "        \"Claude3.5\": \"Claude3.5\",\n",
    "    }\n",
    "\n",
    "    # Start building the LaTeX code\n",
    "    # Start building the LaTeX code\n",
    "    if wrap:\n",
    "        latex_code = \"\"\"\n",
    "\\\\begin{wraptable}[13]{r}{8.7cm}\n",
    "\\\\small\n",
    "\\\\vspace{-10pt}\n",
    "\\\\centering\n",
    "\"\"\"\n",
    "    else:\n",
    "        latex_code = \"\"\"\n",
    "\\\\begin{table}[h]\n",
    "\\\\small\n",
    "\\\\centering\n",
    "\"\"\"\n",
    "    latex_code += (\n",
    "        \"    \\\\begin{tabularx}{8.7cm}{@{\\\\hspace{10pt}}\"\n",
    "        + \"r\" * (len(models) + 2)\n",
    "        + \"@{\\\\hspace{6pt}}}\\n\"\n",
    "    )\n",
    "    latex_code += \"    \\\\toprule\\n\"\n",
    "    latex_code += \"         Dimension & Range \"\n",
    "\n",
    "    # Add model headers to the table\n",
    "    for model in models:\n",
    "        latex_code += f\"& {models_mapping[model]} \"\n",
    "    latex_code += \"\\\\\\\\ \\\\midrule\\n\"\n",
    "\n",
    "    # Populate the table with data\n",
    "    for dim_key, dim_label in dimensions.items():\n",
    "        latex_code += f\"         {dim_label} \"\n",
    "        for model in models:\n",
    "            if model in performance and dim_key in performance[model]:\n",
    "                value = performance[model][dim_key][0]\n",
    "                latex_code += f\"& {value:.2f} \"\n",
    "            else:\n",
    "                latex_code += \"& \"\n",
    "        latex_code += \"\\\\\\\\ \\n\"\n",
    "\n",
    "    # Close the table\n",
    "    latex_code += \"\"\"    \\\\bottomrule\n",
    "    \\\\end{tabularx}\n",
    "    \\\\vspace{-5pt}\n",
    "    \\\\caption{The aggregated performance of each model by averaging across different episodes.}\n",
    "    \\\\label{tab:model_performance}\n",
    "\"\"\"\n",
    "    if wrap:\n",
    "        latex_code += \"\\\\end{wraptable}\\n\"\n",
    "    else:\n",
    "        latex_code += \"\\\\end{table}\\n\"\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = generate_latex_table(\n",
    "    performance=performance_data,\n",
    "    models=[\"gpt-4-turbo\", \"gpt-3.5-turbo\", \"llama3\", \"Claude3.5\"],\n",
    "    wrap=False,\n",
    ")\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk ratio graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## risk ratio graph\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def generate_bar_graph(\n",
    "    ratio_data: Dict[str, Dict[str, Tuple[float, float]]], save_path: str = \"\"\n",
    ") -> None:\n",
    "    # Define the categories to include in the graph\n",
    "    categories = [\n",
    "        \"overall_score\",\n",
    "        \"targeted_safety_risks\",\n",
    "        \"system_and_operational_risks\",\n",
    "        \"content_safety_risks\",\n",
    "        \"societal_risks\",\n",
    "        \"legal_and_rights_related_risks\",\n",
    "    ]\n",
    "    category_acronyms = {\n",
    "        \"overall_score\": \"Overall\",\n",
    "        \"targeted_safety_risks\": \"Tar.R\",\n",
    "        \"system_and_operational_risks\": \"Sys.R\",\n",
    "        \"content_safety_risks\": \"Con.R\",\n",
    "        \"societal_risks\": \"Soc.R\",\n",
    "        \"legal_and_rights_related_risks\": \"Legal.R\",\n",
    "    }\n",
    "\n",
    "    # Initialize data containers for plotting\n",
    "    models = list(ratio_data.keys())\n",
    "    number_of_models = len(models)\n",
    "    category_values = {category: [] for category in categories}\n",
    "\n",
    "    # Extract the data\n",
    "    for model in models:\n",
    "        for category in categories:\n",
    "            value = ratio_data[model].get(category, (0.0, 0.0))[0]\n",
    "            category_values[category].append(value)\n",
    "\n",
    "    # Set up Seaborn's style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Create a new figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))  # Smaller figure size\n",
    "\n",
    "    # Define color palette (blues)\n",
    "    palette = sns.color_palette(\"Blues\", len(models))\n",
    "\n",
    "    # Plot bars for each model\n",
    "    bar_width = 0.2  # Width of the bars\n",
    "    index = range(len(categories))  # X locations for the groups\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        bars = ax.bar(\n",
    "            [p + i * bar_width for p in index],\n",
    "            [category_values[cat][i] for cat in categories],\n",
    "            bar_width,\n",
    "            label=models_mapping[model],\n",
    "            color=palette[i],\n",
    "        )\n",
    "        # Add numbers on top of bars\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                yval + 0.01,\n",
    "                f\"{yval:.2f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=10,\n",
    "            )\n",
    "\n",
    "    # Labels, title, and legend\n",
    "    ax.set_ylabel(\"Risk Ratio\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_xticks([p + (bar_width * (len(models) - 1) / 2) for p in index])\n",
    "    ax.set_xticklabels([category_acronyms[cat] for cat in categories], fontsize=12)\n",
    "    ax.legend(\n",
    "        title=\"Models\",\n",
    "        title_fontsize=\"13\",\n",
    "        fontsize=\"11\",\n",
    "        loc=\"best\",\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "    )\n",
    "    sns.despine()\n",
    "    # Improve visual spacing\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_bar_graph(ratio_data=ratio_data, save_path=\"./risk_ratio_graph.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison across models### Episodes with no target risks but other risks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk Types Basic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from haicosystem.protocols import HaiEnvironmentProfile\n",
    "\n",
    "risk_count = {}\n",
    "\n",
    "for env in HaiEnvironmentProfile.find().all():\n",
    "    risks = (env.risk_type).split(\",\")\n",
    "    for risk in risks:\n",
    "        risk_count[risk] = risk_count.get(risk, 0) + 1\n",
    "\n",
    "print(risk_count.keys())\n",
    "\n",
    "stats = {}\n",
    "\n",
    "most_frequent_risk_type = max(risk_count, key=risk_count.get)\n",
    "stats[\"most_frequent_risk_type\"] = most_frequent_risk_type\n",
    "\n",
    "least_frequent_risk_type = min(risk_count, key=risk_count.get)\n",
    "stats[\"least_frequent_risk_type\"] = least_frequent_risk_type\n",
    "\n",
    "mean_count = statistics.mean(risk_count.values())\n",
    "stats[\"mean_count\"] = mean_count\n",
    "\n",
    "median_count = statistics.median(risk_count.values())\n",
    "stats[\"median_count\"] = median_count\n",
    "\n",
    "stdev_count = statistics.stdev(risk_count.values()) if len(risk_count) > 1 else 0\n",
    "stats[\"stdev_count\"] = stdev_count\n",
    "\n",
    "# Make the bar chart\n",
    "\n",
    "risk_types = list(risk_count.keys())\n",
    "counts = list(risk_count.values())\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(risk_types, counts, color=\"skyblue\")\n",
    "\n",
    "# Graph labels, title, axis readability\n",
    "plt.xlabel(\"Risk Types\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Risk Types\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        str(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Add statistics to the plot\n",
    "stats_text = (\n",
    "    f\"Most Frequent Risk: {stats['most_frequent_risk_type']} ({max(risk_count.values())})\\n\"\n",
    "    f\"Least Frequent Risk: {stats['least_frequent_risk_type']} ({min(risk_count.values())})\\n\"\n",
    "    f\"Mean Count: {stats['mean_count']:.2f}\\n\"\n",
    "    f\"Median Count: {stats['median_count']:.2f}\\n\"\n",
    "    f\"Std Dev: {stats['stdev_count']:.2f}\"\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    0.95,\n",
    "    0.95,\n",
    "    stats_text,\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=12,\n",
    "    verticalalignment=\"top\",\n",
    "    horizontalalignment=\"right\",\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgray\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create Pie Chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    risk_count.values(),\n",
    "    labels=risk_count.keys(),\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=140,\n",
    "    colors=plt.cm.Paired.colors,\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of Risk Types\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### safty and goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_list = [\n",
    "    EpisodeLog.find(EpisodeLog.tag == tags[0]).all(),\n",
    "    EpisodeLog.find(EpisodeLog.tag == tags[1]).all(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a graph group safety and goal as x and y aixs aross different scenarios\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sotopia.database import EpisodeLog\n",
    "\n",
    "from haicosystem.protocols import HaiEnvironmentProfile\n",
    "\n",
    "\n",
    "def plot_safety_goal_scatter(\n",
    "    episodes_list: list[list[EpisodeLog]],\n",
    "    save_path: str = None,\n",
    "    if_show_codename: bool = False,\n",
    ") -> None:\n",
    "    # Extract safety and goal scores from episodes\n",
    "    safety_scores = {}\n",
    "    goal_scores = {}\n",
    "    env_codenames = {}\n",
    "    user_intent = {}\n",
    "    models = []\n",
    "    avg_safety_scores = {}\n",
    "    avg_goal_scores_list = {}\n",
    "    for index, episodes in enumerate(episodes_list):\n",
    "        for episode in episodes:\n",
    "            env = episode.environment\n",
    "            model = episode.models[2]\n",
    "            key = (model, env)\n",
    "            if key not in safety_scores:\n",
    "                safety_scores[key] = []\n",
    "                goal_scores[key] = []\n",
    "            safety_scores[key].append(episode.rewards[1][1][\"targeted_safety_risks\"])\n",
    "            goal_scores[key].append(episode.rewards[1][1][\"goal\"])\n",
    "            models.append(model)\n",
    "            if index == 0:\n",
    "                env_profile = HaiEnvironmentProfile.get(env)\n",
    "                env_codenames[env] = env_profile.codename\n",
    "                user_intent[env] = env_profile.agent_intent_labels[0]\n",
    "\n",
    "    avg_safety_scores = {\n",
    "        key: sum(scores) / len(scores) for key, scores in safety_scores.items()\n",
    "    }\n",
    "    avg_goal_scores = {\n",
    "        key: sum(scores) / len(scores) for key, scores in goal_scores.items()\n",
    "    }\n",
    "    # Count occurrences of (safety_score, goal_score) pairs\n",
    "    score_pairs = list(zip(avg_safety_scores.values(), avg_goal_scores.values()))\n",
    "    pair_counts = Counter(score_pairs)\n",
    "\n",
    "    # Create a scatter plot using seaborn\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "    models_set = set(models)\n",
    "    print(models_set)\n",
    "    assert len(models_set) == 2, \"The function only supports two models for comparison.\"\n",
    "    models_list = list(models_set)\n",
    "    model_colors = {\n",
    "        models_list[0]: {\"benign\": \"#1f77b4\", \"malicious\": \"#d62728\"},  # blue, red\n",
    "        models_list[1]: {\"benign\": \"#2ca02c\", \"malicious\": \"#ff7f0e\"},  # green, orange\n",
    "        # Add more models and their corresponding colors as needed\n",
    "    }\n",
    "\n",
    "    data = []\n",
    "    for key, (safety, goal) in zip(avg_safety_scores.keys(), score_pairs):\n",
    "        model = key[\n",
    "            0\n",
    "        ]  # Assuming the model is the same for all episodes in this context\n",
    "        color = model_colors[model][user_intent[key[1]]]\n",
    "        data.append(\n",
    "            {\n",
    "                \"model\": model,\n",
    "                \"safety\": safety,\n",
    "                \"goal\": goal,\n",
    "                \"size\": pair_counts[(safety, goal)],\n",
    "                \"color\": color,\n",
    "                \"codename\": env_codenames[key[1]] if if_show_codename else \"\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "    sns.set_theme(style=\"whitegrid\", rc=custom_params)\n",
    "\n",
    "    for ax, model in zip(axes, models_list):\n",
    "        model_df = df[df[\"model\"] == model]\n",
    "        scatter_plot = sns.scatterplot(\n",
    "            ax=ax,\n",
    "            data=model_df,\n",
    "            x=\"safety\",\n",
    "            y=\"goal\",\n",
    "            size=\"size\",\n",
    "            sizes=(200, 800),\n",
    "            hue=\"color\",\n",
    "            palette=model_df[\"color\"].unique(),\n",
    "            alpha=0.5,\n",
    "            edgecolor=\"w\",\n",
    "            linewidth=0.5,\n",
    "            legend=False,\n",
    "        )\n",
    "        ax.set_xlabel(\"Safety Score\")\n",
    "        if ax == axes[0]:\n",
    "            ax.set_ylabel(\"Goal Score\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        # Perform regression analysis\n",
    "        reg_plot = sns.regplot(\n",
    "            ax=ax,\n",
    "            data=model_df,\n",
    "            x=\"safety\",\n",
    "            y=\"goal\",\n",
    "            scatter=False,\n",
    "            color=\"purple\",\n",
    "            line_kws={\"linewidth\": 1, \"alpha\": 0.7},\n",
    "        )\n",
    "\n",
    "        # Calculate and show correlation number\n",
    "        correlation = model_df[\"safety\"].corr(model_df[\"goal\"])\n",
    "        ax.annotate(\n",
    "            f\"Correlation: {correlation:.2f}\",\n",
    "            xy=(0.95, 0.05),\n",
    "            xycoords=\"axes fraction\",\n",
    "            fontsize=12,\n",
    "            ha=\"right\",\n",
    "            va=\"bottom\",\n",
    "            color=\"purple\",\n",
    "        )\n",
    "        # Add diagonal line\n",
    "        ax.plot([-10, 0], [0, 10], ls=\"--\", c=\".3\", linewidth=3, alpha=0.3)\n",
    "\n",
    "        if if_show_codename:\n",
    "            for _, row in model_df.iterrows():\n",
    "                ax.text(\n",
    "                    row[\"safety\"], row[\"goal\"], row[\"codename\"], fontsize=9, ha=\"right\"\n",
    "                )\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        wspace=0.1\n",
    "    )  # Adjust the width space between subplots to make them more compact\n",
    "\n",
    "    # Add legend for each color\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    for ax, model in zip(axes, models_list):\n",
    "        legend_elements = []\n",
    "        for intent, color in model_colors[model].items():\n",
    "            legend_elements.append(\n",
    "                Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    marker=\"o\",\n",
    "                    color=\"w\",\n",
    "                    label=f\"{models_mapping[model]} - {intent}\",\n",
    "                    markerfacecolor=color,\n",
    "                    markersize=10,\n",
    "                )\n",
    "            )\n",
    "        ax.legend(handles=legend_elements, title=\"Model - Intent\", loc=\"upper left\")\n",
    "\n",
    "    # Improve visual spacing\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_safety_goal_scatter(\n",
    "    episodes_list, save_path=\"./safety_goal_scatter.pdf\", if_show_codename=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sec 6.2: human intents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from haicosystem.protocols import HaiEnvironmentProfile\n",
    "\n",
    "\n",
    "def calculate_model_rewards(models, tags, remove_tools):\n",
    "    model_rewards = {}\n",
    "    for model, tag in zip(models, tags):\n",
    "        episodes = EpisodeLog.find(EpisodeLog.tag == tag).all()\n",
    "        benign_intent_episodes = []\n",
    "        malicious_intent_episodes = []\n",
    "        for episode in episodes:\n",
    "            env = HaiEnvironmentProfile.get(episode.environment)\n",
    "            tools_or_not = len(env.toolkits) > 0\n",
    "            if remove_tools:\n",
    "                if tools_or_not:\n",
    "                    continue\n",
    "            if env.agent_intent_labels[0] == \"benign\":\n",
    "                benign_intent_episodes.append(episode)\n",
    "            else:\n",
    "                malicious_intent_episodes.append(episode)\n",
    "        try:\n",
    "            benign_binary_avg_rewards = get_avg_reward(\n",
    "                benign_intent_episodes, model, binary=True\n",
    "            )  # type: ignore\n",
    "        except Exception as e:\n",
    "            benign_binary_avg_rewards = {}\n",
    "        malicious_binary_avg_rewards = get_avg_reward(\n",
    "            malicious_intent_episodes, model, binary=True\n",
    "        )  # type: ignore\n",
    "        model_rewards[model] = (benign_binary_avg_rewards, malicious_binary_avg_rewards)\n",
    "    return model_rewards\n",
    "\n",
    "\n",
    "model_rewards = calculate_model_rewards(models, tags, remove_tools=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the plot malicious vs benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "for env in HaiEnvironmentProfile.find().all():\n",
    "    realism_level = env.realism\n",
    "    if (\n",
    "        realism_level != \"level 3\"\n",
    "        and realism_level != \"level 2\"\n",
    "        and realism_level != \"level 1\"\n",
    "    ):\n",
    "        realism_counter[\"level 1\"] += 1\n",
    "    else:\n",
    "        realism_counter[realism_level] += 1\n",
    "\n",
    "# Bar plot for realism level distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(realism_counter.keys(), realism_counter.values(), color=\"lightblue\")\n",
    "\n",
    "plt.xlabel(\"Realism Level\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Realism Levels\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        str(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### malicious intent inferring ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rewards = {}\n",
    "for model, tag in zip(models, tags):\n",
    "    episodes = EpisodeLog.find(EpisodeLog.tag == tag).all()\n",
    "    benign_intent_episodes = []\n",
    "    malicious_intent_episodes = []\n",
    "    for episode in episodes:\n",
    "        env = HaiEnvironmentProfile.get(episode.environment)\n",
    "        tools_or_not = len(env.toolkits) > 0\n",
    "        if tools_or_not:\n",
    "            continue\n",
    "        if env.agent_intent_labels[0] == \"benign\":\n",
    "            benign_intent_episodes.append(episode)\n",
    "        else:\n",
    "            malicious_intent_episodes.append(episode)\n",
    "    print(\n",
    "        f\"the number of the datapoints for goal and risk for each model: {len(malicious_intent_episodes)}\"\n",
    "    )\n",
    "    try:\n",
    "        benign_avg_rewards = get_avg_reward(benign_intent_episodes, model)  # type: ignore\n",
    "    except Exception as e:\n",
    "        benign_avg_rewards = {}\n",
    "    malicious_avg_rewards = get_avg_reward(malicious_intent_episodes, model)  # type: ignore\n",
    "    model_rewards[model] = (benign_avg_rewards, malicious_avg_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_malicious_intent_bar_plot(\n",
    "    data: Dict[\n",
    "        str, Tuple[Dict[str, Tuple[float, float]], Dict[str, Tuple[float, float]]]\n",
    "    ],\n",
    "    save_path: str,\n",
    ") -> None:\n",
    "    # Prepare data for plotting\n",
    "    models = []\n",
    "    goal_scores = []\n",
    "    risk_scores = []\n",
    "    # the second element of the tuple is the malicious intent\n",
    "    for model_name, (benign, malicious) in data.items():\n",
    "        models.append(models_mapping[model_name])\n",
    "        risk_scores.append(malicious[\"targeted_safety_risks\"][0])\n",
    "        goal_scores.append(malicious[\"goal\"][0])\n",
    "    plot_data = {\n",
    "        \"Model\": models + models,\n",
    "        \"Score\": goal_scores + risk_scores,\n",
    "        \"Metric\": [\"Goal\"] * len(goal_scores) + [\"Risk\"] * len(risk_scores),\n",
    "    }\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    custom_palette = {\"Goal\": \"#4dabf7\", \"Risk\": \"#ff6b6b\"}\n",
    "    ax = sns.barplot(\n",
    "        x=\"Model\", y=\"Score\", hue=\"Metric\", data=plot_data, palette=custom_palette\n",
    "    )\n",
    "    ax.set_xlabel(\"\")  # Remove the x-axis label\n",
    "    ax.legend(fontsize=\"small\")  # Set smaller legend\n",
    "\n",
    "    # Add numbers on each bar, excluding 0.0\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        if height != 0.0:  # Only annotate if height is not 0.0\n",
    "            ax.annotate(\n",
    "                format(height, \".2f\"),\n",
    "                (p.get_x() + p.get_width() / 2.0, height),\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                xytext=(0, 9),\n",
    "                textcoords=\"offset points\",\n",
    "            )\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "draw_malicious_intent_bar_plot(model_rewards, save_path=\"./malicious_intent_plot.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sec 6.3: Access to the tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from haicosystem.protocols import HaiEnvironmentProfile\n",
    "\n",
    "# Initialize agent intent label counter\n",
    "intent_counter = Counter()\n",
    "\n",
    "# Gather agent intent label data\n",
    "for env in HaiEnvironmentProfile.find().all():\n",
    "    intents = env.agent_intent_labels\n",
    "    for intent in intents:\n",
    "        intent_counter[intent.strip()] += 1\n",
    "\n",
    "# Data for pie chart\n",
    "labels = intent_counter.keys()\n",
    "sizes = intent_counter.values()\n",
    "colors = plt.cm.Paired.colors  # You can use different color maps\n",
    "\n",
    "\n",
    "# Custom function to format the pie chart labels\n",
    "def func(pct, all_vals):\n",
    "    absolute = int(pct / 100.0 * sum(all_vals))\n",
    "    return f\"{absolute} ({pct:.1f}%)\"\n",
    "\n",
    "\n",
    "# Create Pie Chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    sizes,\n",
    "    labels=labels,\n",
    "    autopct=lambda pct: func(pct, sizes),\n",
    "    startangle=140,\n",
    "    colors=colors,\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of Agent Intent Labels\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from haicosystem.protocols import HaiEnvironmentProfile\n",
    "\n",
    "# Initialize domain counter\n",
    "domain_counter = Counter()\n",
    "\n",
    "# Gather domain data\n",
    "for env in HaiEnvironmentProfile.find().all():\n",
    "    domain = env.domain\n",
    "    domain_counter[domain] += 1\n",
    "\n",
    "# Bar plot for domain distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(domain_counter.keys(), domain_counter.values(), color=\"skyblue\")\n",
    "\n",
    "plt.xlabel(\"Domain\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Domains\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        str(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haicosystem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
